# -*- coding: utf-8 -*-
"""a_fashion_dataset_feature_extractor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MuIZrnRpQcdEs5h9YQx95KFQ-J14Bmse
"""

!nvidia-smi

"""# *Installation*"""

!pip install tez
!pip install efficientnet_pytorch
!pip uninstall albumentations
!pip install albumentations

"""# imports"""

# Commented out IPython magic to ensure Python compatibility.
import os
import albumentations
import  matplotlib.pyplot as plt
import pandas as pd
import cv2

import tez

from tez.datasets import ImageDataset
from tez.callbacks import EarlyStopping

import torch
import torch.nn as nn

import torchvision

from sklearn import metrics, model_selection
from efficientnet_pytorch import EfficientNet
from pathlib import Path
import argparse
import os

import albumentations
import pandas as pd
import numpy as np
import tez
import torch
import torch.nn as nn
from efficientnet_pytorch import EfficientNet
from sklearn import metrics, model_selection, preprocessing
from tez.callbacks import EarlyStopping
from tez.datasets import ImageDataset
from torch.nn import functional as F

from tqdm import tqdm
from pathlib import Path

from torch.utils.data import Dataset, DataLoader


# %matplotlib inline

# img = cv2.imread('/content/13735.webp')
# print(img.shape)
# cv2.imwrite(os.path.join('/content/drive/MyDrive', '13735.jpg'), img)
# cv2.imwrite(os.path.join(IMAGE_PATH, '13735.jpg'), img)

BASE_PATH = '/content/drive/MyDrive/upwork/img'
IMAGE_PATH = '/content/drive/MyDrive/upwork/img/data/fashion-dataset/images'
IMAGE_VECTOR_PATH = '/content/drive/MyDrive/upwork/img/data/fashion-dataset/image_vectors'

"""# Feature Extractor (using a pre-trained model)

## Model
"""

class FeatureExtractorEfficientNet(nn.Module):
    def __init__(self, efficientnet_model_name='efficientnet-b3'):
        super().__init__()
        self.effnet = EfficientNet.from_pretrained(efficientnet_model_name)
        self.out_feature_size = self.effnet._conv_head.out_channels

    def forward(self, image):
        batch_size, _, _, _ = image.shape

        x = self.effnet.extract_features(image)
        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)
        return x

"""## Dataloader"""

class ImageVecDataset(Dataset):

    def __init__(self, IMAGE_PATH, aug=None):
        """
        Args:
            image_dir (string): Path to the images folder.
            aug: augumentation
        """
        self.image_dir = IMAGE_PATH
        self.images = list(Path(self.image_dir).glob('*.jpg'))
        if aug is None:
          self.aug = albumentations.Compose(
              [
                  albumentations.Normalize(
                      mean=[0.485, 0.456, 0.406],
                      std=[0.229, 0.224, 0.225],
                      max_pixel_value=255.0,
                      p=1.0,
                  ),
              ],
              p=1.0,
          )
        else:
          self.aug = aug

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
      filename = str(self.images[idx])
      # print(os.path.isfile(filename))

      try:
          img = cv2.imread(filename)
          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
          img = cv2.resize(img,(256,256))
          img = torch.from_numpy(self.aug(image=img)['image']).type(torch.FloatTensor)
          img = img.permute(2, 0, 1)
      except:
          print(filename)
          img = torch.rand((3, 256, 256)).type(torch.FloatTensor)
        

      return str(self.images[idx].stem), img

"""## Feature Extraction"""

image_path_list = list(Path(IMAGE_PATH).glob('*.jpg'))
print('Number of images: ', len(image_path_list))


fashion_dataset = ImageVecDataset(IMAGE_PATH)
fashion_dataloader = DataLoader(fashion_dataset, batch_size=8, shuffle=False, num_workers=4)

feature_extractor = FeatureExtractorEfficientNet()
feature_extractor.cuda()
feature_extractor.eval()

for i, (filenames, images) in tqdm(enumerate(fashion_dataloader), total=len(fashion_dataloader)):
  image_vector = feature_extractor(images.cuda()).cpu().detach().numpy()
  for i in range(len(images)):
      np.save(os.path.join(IMAGE_VECTOR_PATH, f'{filenames[i]}.npy'), image_vector[i])

# !rm -rf '/content/drive/MyDrive/upwork/img/data/fashion-dataset/image_vectors'

!unzip '/content/drive/MyDrive/upwork/img/data/fashion-dataset/image_vectors.zip' -d '/content/drive/MyDrive/upwork/img/data/fashion-dataset/images/vectors'

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/upwork/img/styles.csv', error_bad_lines=False)

df.head()

images = os.listdir(IMAGE_PATH)
count = 0
for i in df.id.tolist():
  if str(i) + '.jpg' not in images:
    count += 1
count

df.shape

15281+29163

df.gender.unique()

def encode_label(df, column):
  if column not in df.columns:
    print(f"column: {column} nor present in dataframe")
    le = preprocessing.LabelEncoder()
    le.fit(df[column].tolist())
    print("Number of classes: ", len(le.classes_))
    return le.transform(df[column].tolist())

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
le.fit(df.gender.tolist())
le.classes_

le.transform(df.gender.tolist())[:20]

df.gender.tolist()[:20]

